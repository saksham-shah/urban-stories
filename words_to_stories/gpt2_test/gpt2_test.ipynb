{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "Error",
     "evalue": "Jupyter cannot be started. Error attempting to locate jupyter: Data Science libraries notebook and jupyter are not installed in interpreter Python 3.9.0 64-bit.",
     "traceback": [
      "Error: Jupyter cannot be started. Error attempting to locate jupyter: Data Science libraries notebook and jupyter are not installed in interpreter Python 3.9.0 64-bit.",
      "at b.startServer (c:\\Users\\saksh\\.vscode\\extensions\\ms-python.python-2020.6.91350\\out\\client\\extension.js:48:288041)",
      "at processTicksAndRejections (internal/process/task_queues.js:85:5)",
      "at async b.createServer (c:\\Users\\saksh\\.vscode\\extensions\\ms-python.python-2020.6.91350\\out\\client\\extension.js:48:287483)",
      "at async connect (c:\\Users\\saksh\\.vscode\\extensions\\ms-python.python-2020.6.91350\\out\\client\\extension.js:48:413515)",
      "at async P.ensureConnectionAndNotebookImpl (c:\\Users\\saksh\\.vscode\\extensions\\ms-python.python-2020.6.91350\\out\\client\\extension.js:24:434959)",
      "at async P.ensureConnectionAndNotebook (c:\\Users\\saksh\\.vscode\\extensions\\ms-python.python-2020.6.91350\\out\\client\\extension.js:24:434637)",
      "at async P.clearResult (c:\\Users\\saksh\\.vscode\\extensions\\ms-python.python-2020.6.91350\\out\\client\\extension.js:24:430563)",
      "at async P.reexecuteCell (c:\\Users\\saksh\\.vscode\\extensions\\ms-python.python-2020.6.91350\\out\\client\\extension.js:24:416935)",
      "at async P.reexecuteCells (c:\\Users\\saksh\\.vscode\\extensions\\ms-python.python-2020.6.91350\\out\\client\\extension.js:24:413738)"
     ]
    }
   ],
   "source": [
    "!pip install -q gpt-2-simple\n",
    "import gpt_2_simple as gpt2\n",
    "import requests\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"774M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2.download_gpt2(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = gpt2.start_tf_sess()\n",
    "gpt2.load_gpt2(sess, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateWithPrefix(sess, prefix, length=100, include_prefix=True):\n",
    "  return gpt2.generate(sess,\n",
    "              model_name=model_name,\n",
    "              prefix=prefix,\n",
    "              length=length,\n",
    "              temperature=0.7,\n",
    "              top_p=0.9,\n",
    "              include_prefix=include_prefix,\n",
    "              return_as_list=True\n",
    "              )[0]\n",
    "\n",
    "def getPartOfSpeech(word):\n",
    "  result = requests.get(\"https://api.dictionaryapi.dev/api/v2/entries/en/\" + word)\n",
    "\n",
    "  if result.status_code != 200:\n",
    "    return None\n",
    "  \n",
    "  json = result.json()\n",
    "  return json[0][\"meanings\"][0][\"partOfSpeech\"]\n",
    "\n",
    "# getPartOfSpeech(\"table\")\n",
    "def replacePartOfSpeech(sentence, word, partOfSpeech):\n",
    "  sentence += \" \"\n",
    "  output = \"\"\n",
    "  currentWord = \"\"\n",
    "  for char in sentence:\n",
    "    if char >= 'a' and char <= 'z':\n",
    "      currentWord += char\n",
    "    else:\n",
    "      if (len(word) > 0):\n",
    "        # end of word\n",
    "        wordPartOfSpeech = getPartOfSpeech(currentWord)\n",
    "        if (wordPartOfSpeech == partOfSpeech and random.uniform(0, 1) > 0.5):\n",
    "          output += word\n",
    "          return output\n",
    "        else:\n",
    "          output += currentWord\n",
    "        currentWord = \"\"\n",
    "      output += char\n",
    "\n",
    "  return None\n",
    "\n",
    "def insertWordAndTruncate(sentence, word):\n",
    "  partOfSpeech = getPartOfSpeech(word)\n",
    "  return replacePartOfSpeech(sentence, word, partOfSpeech)\n",
    "\n",
    "def generateWithKeywords(sess, prefix, keywords):\n",
    "  output = prefix\n",
    "  for word in keywords:\n",
    "    attempts = 0\n",
    "    addition = None\n",
    "    while (attempts < 5 and addition == None):\n",
    "      # output += \" \"\n",
    "      print(\"Prefix: \" + output)\n",
    "      print(\"Word: \" + word)\n",
    "      generated = generateWithPrefix(sess, output, 20 + attempts * 10)\n",
    "      print(\"Generated: \" + generated)\n",
    "      addition = insertWordAndTruncate(generated[len(output):], word)\n",
    "      print(\"Truncated: \" + str(addition))\n",
    "      \n",
    "      attempts += 1\n",
    "    if (addition != None):\n",
    "      output += addition\n",
    "  \n",
    "  output = generateWithPrefix(sess, output, 20)\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story = generateWithKeywords(sess, \"Once upon a time, \", [\"shower\", \"mountain\", \"gear\"])\n",
    "print(str(story))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}